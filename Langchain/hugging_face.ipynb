{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calling Hugging Face Login",
   "id": "4f5e735ab358c98e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:44:13.762855Z",
     "start_time": "2025-11-29T12:44:12.635704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()   # you'll paste your HF key once\n"
   ],
   "id": "9efa23a8bb5c27a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e62efce851d48bfb3c9f8ebb6f520c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize a Model from Hugging Face",
   "id": "b28a27ffc784902b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=model, verbose=True)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Invoke API",
   "id": "f50e132ea77347d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:44:43.593499Z",
     "start_time": "2025-11-29T12:44:26.871191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "base = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    task=\"conversational\",     # Qwen supports chat completions\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=base, verbose=True)\n",
    "\n",
    "print(chat.invoke(\"Explain Qunatum Physics simple terms.\"))\n"
   ],
   "id": "a5c5ef50623e26be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Sure! Quantum physics is a branch of physics that deals with the behavior of tiny particles, like atoms and subatomic particles such as electrons and photons. It's a bit different from the classical physics we learn in school because it describes the world at a very small scale, where things can behave in very strange and unexpected ways.\\n\\nHere are some key concepts explained in simple terms:\\n\\n1. **Particles and Waves**: In quantum physics, particles can sometimes act like waves and waves can act like particles. For example, light can behave as both a particle (photon) and a wave. This is known as wave-particle duality.\\n\\n2. **Quantum Superposition**: Imagine a coin spinning in the air. It's not heads or tails until it lands. In quantum physics, particles can exist in multiple states at the same time until they are observed. This is called superposition. For example, an electron can be in multiple places at once until it is measured.\\n\\n3. **Quantum Entanglement**: When particles become entangled, the state of one particle is directly connected to the state of another, no matter how far apart they are. If you change the state of one particle, the other particle will instantly change its state too. This is a bit like having two coins that are magically linked so that if you flip one, the other will flip the same way, even if they are on opposite sides of the world.\\n\\n4. **Uncertainty Principle**: This principle, introduced by Werner Heisenberg, states that you can't know both the exact position and the exact speed of a particle at the same time. The more precisely you know one, the less precisely you can know the other. It's not just a limitation of our measuring tools but a fundamental property of nature.\\n\\n5. **Quantum Tunneling**: This is a phenomenon where particles can pass through barriers that they classically shouldn't be able to pass. It's like a ball being able to go through a wall, which seems impossible in our everyday experience but is real in the quantum world.\\n\\nQuantum physics is full of these strange and fascinating phenomena, and it has led to many technological advancements, such as lasers, semiconductors, and quantum computers. While it can be mind-bending, it's also incredibly powerful and has helped us understand the universe in ways we couldn't before.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 480, 'prompt_tokens': 38, 'total_tokens': 518}, 'model_name': 'Qwen/Qwen2.5-7B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='lc_run--1887a312-14be-4afe-8ea8-4bcdb8de9d00-0' usage_metadata={'input_tokens': 38, 'output_tokens': 480, 'total_tokens': 518}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "questions = [\n",
    "    \"What is RAG?\",\n",
    "    \"Explain LangChain.\",\n",
    "    \"What's the difference between LLM and embedding models?\"\n",
    "]\n",
    "\n",
    "answers = chat.batch(questions)\n",
    "\n",
    "for a in answers:\n",
    "    print(\"\\n---\\n\", a)\n",
    "\n"
   ],
   "id": "2dd48ae27779f20e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in chat.stream(\"Tell me a short story about a robot learning emotions.\"):\n",
    "    print(chunk, end=\"\")\n"
   ],
   "id": "4b0479323e2d92f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output Parsers in Langchain",
   "id": "5771ef79c94a7af2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Return JSON only.\"),\n",
    "    (\"user\", \"{q}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat | parser\n",
    "\n",
    "print(chain.invoke({\"q\": \"Give 3 animals and 1 fact each.\"}))\n"
   ],
   "id": "a4ce2f6bfca359b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import dateparser\n",
    "\n",
    "text = \"Schedule a meeting next Tuesday at 3pm\"\n",
    "\n",
    "# 1. Ask model to rewrite as a clean date expression\n",
    "llm_output = chat.invoke(f\"Convert this to a precise datetime: {text}\")\n",
    "\n",
    "# Extract the message content (string)\n",
    "model_text = llm_output.content\n",
    "\n",
    "# 2. Parse using dateparser\n",
    "parsed_date = dateparser.parse(model_text)\n",
    "\n",
    "print(\"LLM said:\", model_text)\n",
    "print(\"Parsed datetime:\", parsed_date)\n"
   ],
   "id": "7a8ae8e739491187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import (\n",
    "    JsonOutputParser,\n",
    "    CommaSeparatedListOutputParser\n",
    ")\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Parsers\n",
    "json_parser = JsonOutputParser()\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer in the requested format.\"),\n",
    "    (\"user\", \"{q}\")\n",
    "])\n",
    "\n",
    "# Wrap the branches in RunnableParallel\n",
    "parallel_chain = RunnableParallel(\n",
    "    as_list = prompt | chat | list_parser,\n",
    "    as_json = prompt | chat | json_parser\n",
    ")\n",
    "\n",
    "# Invoke\n",
    "result = parallel_chain.invoke({\n",
    "    \"q\": \"Give me 3 animals. Format 1: comma-separated. Format 2: JSON.\"\n",
    "})\n",
    "\n",
    "print(result)\n"
   ],
   "id": "556fa423e6289547",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### New Way of Short Term Memory Langchain",
   "id": "c16801e2ccc6d08e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# simple tool\n",
    "def get_name():\n",
    "    return \"This tool doesn't do much.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=chat,                 # your Qwen ChatHuggingFace model\n",
    "    tools=[],\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "# first turn\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Sahana.\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"123\"}},\n",
    ")\n",
    "\n",
    "# second turn (memory persists automatically)\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"123\"}},\n",
    ")\n",
    "\n",
    "print(response)\n"
   ],
   "id": "b12e528ef68586ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RAG Flow",
   "id": "72f15d0c64e62e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:11.568419Z",
     "start_time": "2025-11-29T12:44:57.430085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ],
   "id": "aa493d7037e4fd3c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:21.311851Z",
     "start_time": "2025-11-29T12:45:21.300652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "dolphin_docs = [\n",
    "    Document(page_content=\"\"\"\n",
    "    Dolphins are highly intelligent marine mammals known for their social behavior.\n",
    "    They belong to the family Delphinidae and communicate using whistles and clicks.\n",
    "    \"\"\"),\n",
    "\n",
    "    Document(page_content=\"\"\"\n",
    "    Dolphins use echolocation to navigate and hunt. They emit sound waves and\n",
    "    interpret the echoes to understand their surroundings.\n",
    "    \"\"\"),\n",
    "\n",
    "    Document(page_content=\"\"\"\n",
    "    The bottlenose dolphin is one of the most well-known species. They live in warm\n",
    "    and temperate seas worldwide and can reach speeds of over 30 km/h.\n",
    "    \"\"\"),\n",
    "\n",
    "    Document(page_content=\"\"\"\n",
    "    Dolphins sleep by shutting down one half of their brain at a time. This allows them\n",
    "    to rest while still surfacing for air.\n",
    "    \"\"\"),\n",
    "\n",
    "    Document(page_content=\"\"\"\n",
    "    Dolphins have complex social structures and often travel in pods. They show signs\n",
    "    of empathy and cooperative behavior, including helping injured members.\n",
    "    \"\"\"),\n",
    "]\n"
   ],
   "id": "6c114aff74e52fcf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:25.082604Z",
     "start_time": "2025-11-29T12:45:24.995362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a dolphin expert. Use ONLY the context to answer.\\n\\n\"\n",
    "     \"Context:\\n{context}\\n\"\n",
    "    ),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n"
   ],
   "id": "7b0ef5007e344a18",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:28.694200Z",
     "start_time": "2025-11-29T12:45:28.685879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n"
   ],
   "id": "615a3e64ca4deed8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:31.306524Z",
     "start_time": "2025-11-29T12:45:30.897666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(dolphin_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n"
   ],
   "id": "ec207590c7773db9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:33.283939Z",
     "start_time": "2025-11-29T12:45:33.276170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        docs = retriever,\n",
    "        question = RunnablePassthrough()\n",
    "    )\n",
    "    | (lambda x: {\n",
    "        \"context\": combine_docs(x[\"docs\"]),\n",
    "        \"question\": x[\"question\"],\n",
    "    })\n",
    "    | prompt\n",
    "    | chat\n",
    ")\n"
   ],
   "id": "b1a85e7e6fe00f6b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:45:39.959346Z",
     "start_time": "2025-11-29T12:45:38.758868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer = rag_chain.invoke(\"How do dolphins sleep?\")\n",
    "print(answer.content)\n"
   ],
   "id": "55b9818dd9fbb734",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dolphins sleep by shutting down one half of their brain at a time, allowing them to rest while still surfacing for air.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:46:02.944280Z",
     "start_time": "2025-11-29T12:46:01.696749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer = rag_chain.invoke(\"How does cat meows\")\n",
    "print(answer.content)"
   ],
   "id": "3a5363bc5c7af2e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context provided is about dolphins, so it does not contain information about how cats meow. Based on general knowledge, cats meow as a form of communication. They use meows to interact with humans and other cats, often to get attention, express needs, or convey emotions. However, this information is not derived from the given context.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Langsmith Tracing",
   "id": "18e1e183e6b7120b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:11:34.845406Z",
     "start_time": "2025-11-29T13:11:34.812263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "id": "46987cdd952ff2e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:12:59.149945Z",
     "start_time": "2025-11-29T13:12:59.141238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def rag_function(query: str):\n",
    "    return rag_chain.invoke(query).content\n",
    "\n",
    "rag_runnable = RunnableLambda(lambda x: rag_function(x[\"question\"]))\n",
    "\n"
   ],
   "id": "3545fdb75a4178cb",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:19:24.591388Z",
     "start_time": "2025-11-29T13:19:23.584888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langsmith as ls\n",
    "\n",
    "with ls.tracing_context(project_name=\"dolphin-rag\", enabled=True):\n",
    "    rag_chain.invoke(\"How do dolphins sleep?\")\n",
    "\n"
   ],
   "id": "33bb038303ee9d82",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:27:14.387483Z",
     "start_time": "2025-11-29T13:27:12.159112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with ls.tracing_context(project_name=\"dolphin-rag\", enabled=True):\n",
    "    rag_chain.invoke(\"What are key features of dolphins?\")"
   ],
   "id": "46a02b6e69ebd69b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Basic Tool Calling",
   "id": "cdd941362005746e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import webcolors\n",
    "def closest_color(requested_color):\n",
    "    min_colors = {}\n",
    "    for key, name in webcolors.CSS3_HEX_TO_NAMES.items():\n",
    "        r, g, b = webcolors.hex_to_rgb(key)\n",
    "        rd = (r - requested_color[0]) ** 2\n",
    "        gd = (g - requested_color[1]) ** 2\n",
    "        bd = (b - requested_color[2]) ** 2\n",
    "        min_colors[(rd + gd + bd)] = name\n",
    "    return min_colors[min(min_colors.keys())]"
   ],
   "id": "2e135b108136d48f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def color_name(r: int, g: int, b: int) -> str:\n",
    "    \"\"\"Given RGB values, return the closest CSS color name.\"\"\"\n",
    "    try:\n",
    "        return webcolors.rgb_to_name((r, g, b))\n",
    "    except ValueError:\n",
    "        return closest_color((r, g, b))\n",
    "\n",
    "@tool\n",
    "def color_mix(r1: int, g1: int, b1: int, r2: int, g2: int, b2: int) -> dict:\n",
    "    \"\"\"Mix two RGB colors and return a dictionary with:\n",
    "    - mixed RGB\n",
    "    - closest CSS color name\n",
    "    \"\"\"\n",
    "    mixed = (\n",
    "        (r1 + r2) // 2,\n",
    "        (g1 + g2) // 2,\n",
    "        (b1 + b2) // 2,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        name = webcolors.rgb_to_name(mixed)\n",
    "    except ValueError:\n",
    "        name = closest_color(mixed)\n",
    "\n",
    "    return {\"mixed_rgb\": mixed, \"mixed_color_name\": name}\n",
    "\n"
   ],
   "id": "ebb605a42e1dd09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "base = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    task=\"conversational\",\n",
    "    max_new_tokens=300,\n",
    ")\n",
    "\n",
    "tools = [color_name, color_mix]\n",
    "\n",
    "chat = ChatHuggingFace(\n",
    "    llm=base,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "16529e8dc78d399e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(chat.invoke(\"What color is rgb(135, 206, 250)?\"))",
   "id": "8007eabd2069ae42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(chat.invoke(\n",
    "    \"Mix rgb(255, 0, 0) with rgb(0, 0, 255). What color do we get?\"\n",
    "))"
   ],
   "id": "d8feff3154a6d515"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(chat.invoke(\"Find the name of rgb(240, 248, 255)\"))",
   "id": "d3ad61f64b7f7e90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e6f939d001561bd1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
